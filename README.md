# Brain-inspired Spatial Cognition for Navigation

<table>
  <tr>
    <td align="center">
      <img src="./assets/demo-1.gif" height="180" alt="GIF 1">
    </td>
    <td align="center">
      <img src="./assets/demo-2.gif" height="200" alt="GIF 2">
    </td>
    <td align="center">
      <img src="./assets/demo-3.gif" height="200" alt="GIF 3">
    </td>
    <td align="center">
      <img src="./assets/demo-4.gif" height="180" alt="GIF 4">
    </td>
  </tr>
</table>

This repository is the official implementation of our paper (From reactive to cognitive: brain-inspired spatial intelligence for embodied agents) 

by [Shouwei Ruan](https://heathcliff-saku.github.io/), [Liyuan Wang](https://lywang3081.github.io/), Caixin Kang, Qihui Zhu, Songming Liu, Xingxing Wei and [Hang Su](https://scholar.google.com/citations?user=dxN1_X0AAAAJ&hl=en), Collaboration between Tsinghua and Beihang University.


![framework](/assets/framework.jpeg "framework")

We proposed BSC-Nav (Brain-inspired spatial cognition for navigation), which leverages bio-inspired spatial cognition mechanisms to continuously understand the surrounding environment by constructing structured spatial memory, supporting general navigation and more advanced spatial intelligence. Our paper is currently under review, and all features will be made publicly available in the near future.

### ğŸ§ Environment & Dataset preparation

### ğŸ® Quick start with BSC-Nav !


### ğŸ¯ Benchmarks


### ğŸ“† TODO
- [x] Upload all experimental scripts for both simulator and real environments
- [ ] Release general navigation reproduction instructions
- [ ] Provide vision-language navigation and A-EQA documentation for reproduction
- [ ] Provide physical environment navigation and mobile manipulation reproduction instructions

### ğŸ¤— Contact

If you have any questions or suggestions, look forward to your contact with us:

Shouwei Ruan: shouweiruan@buaa.edu.cn
